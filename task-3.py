# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nVWFkL2R6DQN0YYimQqbKKhEFfreaSJb

**SCRAPING TEXT,LINKS AND IMAGES FROM WEB PAGES**
"""

import requests
from bs4 import BeautifulSoup

import requests
from bs4 import BeautifulSoup

# Function to fetch HTML content from a URL
def fetch_html(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad status codes
        return response.content
    except requests.RequestException as e:
        print(f"Failed to fetch {url}: {e}")
        return None

# Function to extract paragraphs
def extract_paragraphs(soup):
    paragraphs = soup.find_all('p')
    print("Paragraphs:")
    for paragraph in paragraphs:
        print(paragraph.get_text())
    print("\n")

# Function to extract headings
def extract_headings(soup):
    headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
    print("Headings:")
    for heading in headings:
        print(heading.get_text())
    print("\n")

# Function to extract links
def extract_links(soup):
    links = soup.find_all('a', href=True)
    print("Links:")
    for link in links:
        print(link['href'])
    print("\n")

# Function to extract image sources
def extract_images(soup):
    images = soup.find_all('img', src=True)
    print("Image Sources:")
    for image in images:
        print(image['src'])
    print("\n")

# Function to extract metadata
def extract_metadata(soup):
    metadata = soup.find_all('meta')
    print("Metadata:")
    for meta in metadata:
        print(meta.attrs)
    print("\n")

# Function to extract script tags
def extract_scripts(soup):
    scripts = soup.find_all('script')
    print("Script Tags:")
    for script in scripts:
        print(script.get('src'))
    print("\n")

# Function to extract styles
def extract_styles(soup):
    styles = soup.find_all('style')
    print("Styles:")
    for style in styles:
        print(style.get_text())
    print("\n")

# Function to scrape data from a webpage
def scrape_webpage(url):
    html_content = fetch_html(url)
    if html_content:
        soup = BeautifulSoup(html_content, 'html.parser')

        extract_paragraphs(soup)
        extract_headings(soup)
        extract_links(soup)
        extract_images(soup)
        extract_metadata(soup)
        extract_scripts(soup)
        extract_styles(soup)
    else:
        print(f"Failed to fetch {url}")

# URL of the webpage to scrape (Netflix)
url = 'https://www.netflix.com/'

# Scrape data from the webpage
scrape_webpage(url)